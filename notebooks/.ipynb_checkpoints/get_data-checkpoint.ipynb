{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dbfread import DBF\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import ee\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "import csv\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import logging\n",
    "import json\n",
    "\n",
    "# Configuration du logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from time import sleep\n",
    "from pyproj import Transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_Year\n",
      "-9999    11.881509\n",
      "1988      8.449792\n",
      "1989      6.987536\n",
      "1997      4.289645\n",
      "1990      4.030648\n",
      "           ...    \n",
      "1945      0.053958\n",
      "1953      0.016187\n",
      "1942      0.010792\n",
      "1938      0.005396\n",
      "1941      0.005396\n",
      "Name: proportion, Length: 68, dtype: Float64\n",
      "\n",
      "Années uniques dans les profils géoréférencés : <IntegerArray>\n",
      "[ 1957,  1963,  1962,  1966,  1960,  1954,  1958,  1965,  1964,  1956,  1952,\n",
      "  1961,  1969,  1955,  1959,  1968,  1970,  1951,  1967,  1986,  1997,  1980,\n",
      "  1981,  1984,  1982,  1983,  1987, -9999,  1996,  1995,  1994,  1998,  1999,\n",
      "  1988,  1990,  1991,  1977,  1989,  1985,  1979,  1992,  1978,  1974,  1976,\n",
      "  1973,  1975,  1971,  2000,  2004,  1993,  2003,  2002,  1972,  2001,  2006,\n",
      "  2007,  2008,  1941,  1938,  1945,  2009,  2005,  1942,  1944,  2010,  1946,\n",
      "  1953,  2011]\n",
      "Length: 68, dtype: Int64\n",
      "before filtering: (18533, 4)\n",
      "after filtering year: (10794, 4)\n",
      "after filtering coordinates: (10425, 4)\n",
      "after removing duplicates: (9481, 4)\n"
     ]
    }
   ],
   "source": [
    "# Lire les couches\n",
    "\n",
    "\n",
    "profiles = pd.DataFrame(iter(DBF('../data/use/afsp/GIS_Dbf/AfSP012Qry_Profiles.dbf', encoding='latin-1')))\n",
    "\n",
    "profiles\n",
    "\n",
    "\n",
    "geo = gpd.read_file('../data/use/afsp/GIS_Shape/AfSP012Qry_GeoPoints.shp')\n",
    "geo['Longitude'] = geo.geometry.x\n",
    "geo['Latitude'] = geo.geometry.y\n",
    "\n",
    "\n",
    "\n",
    "# Fusionner les deux sur 'ProfileID'\n",
    "merged = pd.merge(profiles, geo[['ProfileID', 'Longitude', 'Latitude']], on='ProfileID', how='left')\n",
    "profiles_ = merged.dropna(subset=['Longitude', 'Latitude'])\n",
    "\n",
    "# Afficher les profils géoréférencés\n",
    "profiles_ = profiles_[['ProfileID', 'Longitude', 'Latitude','T_Year']]\n",
    "#convert the T_Year to int\n",
    "profiles_['T_Year'] = pd.to_numeric(profiles_['T_Year'], errors='coerce').astype('Int64')\n",
    "# afficher toute les date avec le poucentage de chaque année\n",
    "year_counts = profiles_['T_Year'].value_counts(normalize=True) * 100\n",
    "# print(\"\\nPourcentage de profils par année :\")\n",
    "print(year_counts)\n",
    "\n",
    "# Afficher les années avec le pourcentage\n",
    "year_counts = year_counts.reset_index()\n",
    "profiles_\n",
    "\n",
    "#afficher les années  unique\n",
    "unique_years = profiles_['T_Year'].unique()\n",
    "print(\"\\nAnnées uniques dans les profils géoréférencés :\", unique_years)\n",
    "\n",
    "print(\"before filtering:\", profiles_.shape)\n",
    "profiles_ = profiles_[profiles_['T_Year'] >= 1982 ]\n",
    "# profiles_ = profiles_[ profiles_['T_Year'] <= 2013]\n",
    "print(\"after filtering year:\", profiles_.shape)\n",
    "available_years = profiles_['T_Year'].unique()\n",
    "\n",
    "# print(\"available years:\", pd.Series(available_years).sort_values())\n",
    "\n",
    "# filter longitude and latitude\n",
    "profiles_ = profiles_[(profiles_['Longitude'] != 0.0) &\n",
    "                        (profiles_['Latitude'] != 0.0) &\n",
    "                        (profiles_['Longitude'].notnull()) &\n",
    "                        (profiles_['Latitude'].notnull())]\n",
    "print(\"after filtering coordinates:\", profiles_.shape)  \n",
    "\n",
    "profiles_ = profiles_.drop_duplicates(subset=['Longitude', 'Latitude'], keep='first')\n",
    "print(\"after removing duplicates:\", profiles_.shape)\n",
    "\n",
    "\n",
    "profiles_list_afsp =  profiles_[['ProfileID', 'Longitude', 'Latitude','T_Year']].values.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ird_data =  pd.read_csv(\\'../data/use/ird/Data_to_Analyze.csv\\',)\\n\\n\\ntr = Transformer.from_crs(32628, 4326, always_xy=True)\\nird_data[[\"lon\", \"lat\"]] = ird_data.apply(\\n    lambda r: tr.transform(r[\"X_Centroid\"], r[\"Y_Centroid\"]),\\n    axis=1, result_type=\"expand\"\\n)\\n\\nird_data = ird_data.drop(columns=[\"X_Centroid\", \"Y_Centroid\"])\\nird_data = ird_data.rename(columns={\"lon\": \"Longitude\", \"lat\": \"Latitude\", \"Profile_id\": \"ProfileID\"})\\n# ird_data = ird_data.drop_duplicates(subset=[\"geometry\"], keep=\"first\")\\nprofiles_ird = ird_data[[\\'ProfileID\\', \\'Longitude\\', \\'Latitude\\']]\\nprofiles_ird = profiles_ird.drop_duplicates(subset=[\\'Longitude\\', \\'Latitude\\'], keep=\\'first\\', ignore_index=True)\\n\\nprofiles_ird[\"T_Year\"] = 2016\\nprofiles_ird '"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" ird_data =  pd.read_csv('../data/use/ird/Data_to_Analyze.csv',)\n",
    "\n",
    "\n",
    "tr = Transformer.from_crs(32628, 4326, always_xy=True)\n",
    "ird_data[[\"lon\", \"lat\"]] = ird_data.apply(\n",
    "    lambda r: tr.transform(r[\"X_Centroid\"], r[\"Y_Centroid\"]),\n",
    "    axis=1, result_type=\"expand\"\n",
    ")\n",
    "\n",
    "ird_data = ird_data.drop(columns=[\"X_Centroid\", \"Y_Centroid\"])\n",
    "ird_data = ird_data.rename(columns={\"lon\": \"Longitude\", \"lat\": \"Latitude\", \"Profile_id\": \"ProfileID\"})\n",
    "# ird_data = ird_data.drop_duplicates(subset=[\"geometry\"], keep=\"first\")\n",
    "profiles_ird = ird_data[['ProfileID', 'Longitude', 'Latitude']]\n",
    "profiles_ird = profiles_ird.drop_duplicates(subset=['Longitude', 'Latitude'], keep='first', ignore_index=True)\n",
    "\n",
    "profiles_ird[\"T_Year\"] = 2016\n",
    "profiles_ird \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ird_data =  pd.read_csv('../data/use/ird/all_profiles.csv',)\n",
    "\n",
    "\n",
    "tr = Transformer.from_crs(32628, 4326, always_xy=True)\n",
    "ird_data[[\"Longitude\", \"Latitude\"]] = ird_data.apply(\n",
    "    lambda r: tr.transform(r[\"X_Centroid\"], r[\"Y_Centroid\"]),\n",
    "    axis=1, result_type=\"expand\"\n",
    ")\n",
    "\n",
    "ird_data = ird_data.drop(columns=[\"X_Centroid\", \"Y_Centroid\"])\n",
    "ird_data = ird_data.rename(columns={\"Date\": \"T_Year\"})\n",
    "\n",
    "ird_data['ProfileID'] = ird_data.index\n",
    "# ird_data = ird_data.drop_duplicates(subset=[\"geometry\"], keep=\"first\")\n",
    "profiles_ird = ird_data[['ProfileID', 'Longitude', 'Latitude', 'T_Year']]\n",
    "profiles_ird = profiles_ird.drop_duplicates(subset=['Longitude', 'Latitude'], keep='first', ignore_index=True)\n",
    "profiles_ird['ProfileID'] =profiles_ird.index.map(lambda x: f'IRD_{x+1}')  # Assign unique ProfileID based on index\n",
    "# ProfileID  = Point(longitude, latitude)\n",
    "map_longitude_latitude_profile_id = profiles_ird.set_index(['Longitude', 'Latitude'])['ProfileID'].to_dict()\n",
    "# profiles_ird[\"T_Year\"] = 2016\n",
    "# conver T_Year '01/01/2016' to int(2016)\n",
    "profiles_ird['T_Year'] = profiles_ird['T_Year'].apply(lambda x: int(x.split(\"/\")[-1]))\n",
    "profiles_ird\n",
    "# map_longitude_latitude_profile_id\n",
    "# save map_longitude_latitude_profile_id  as pd\n",
    "map_longitude_latitude_profile_id_df = pd.DataFrame(list(map_longitude_latitude_profile_id.items()), columns=['Longitude_Latitude', 'ProfileID'])\n",
    "map_longitude_latitude_profile_id_df.to_csv('../data/use/ird/map_longitude_latitude_profile_id.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['profile_id', 'profile_code', 'dataset_code', 'site_id',\n",
      "       'positional_uncertainty', 'country_name', 'longitude', 'latitude',\n",
      "       'wrb_reference_soil_group_code', 'wrb_reference_soil_group',\n",
      "       'wrb_prefix_qualifiers', 'wrb_suffix_qualifiers',\n",
      "       'wrb_principal_qualifiers', 'wrb_supplementary_qualifiers',\n",
      "       'wrb_publication_year', 'fao_major_group_code', 'fao_major_group',\n",
      "       'fao_soil_unit_code', 'fao_soil_unit', 'fao_publication_year',\n",
      "       'usda_order_name', 'usda_suborder', 'usda_subgroup', 'usda_great_group',\n",
      "       'usda_publication_year'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProfileID</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>T_Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1144360</td>\n",
       "      <td>-15.495200</td>\n",
       "      <td>13.932300</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1144361</td>\n",
       "      <td>-14.838810</td>\n",
       "      <td>14.565890</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1144362</td>\n",
       "      <td>-15.515833</td>\n",
       "      <td>14.164722</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1144363</td>\n",
       "      <td>29.430000</td>\n",
       "      <td>-2.060000</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1144364</td>\n",
       "      <td>29.590000</td>\n",
       "      <td>-2.070000</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28900</th>\n",
       "      <td>1691332</td>\n",
       "      <td>19.112700</td>\n",
       "      <td>47.627899</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28901</th>\n",
       "      <td>1691333</td>\n",
       "      <td>19.962099</td>\n",
       "      <td>47.432400</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28902</th>\n",
       "      <td>1691334</td>\n",
       "      <td>20.952499</td>\n",
       "      <td>46.399300</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28903</th>\n",
       "      <td>1691335</td>\n",
       "      <td>-1.300000</td>\n",
       "      <td>34.916698</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28904</th>\n",
       "      <td>1691336</td>\n",
       "      <td>19.291800</td>\n",
       "      <td>47.806099</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18976 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ProfileID  Longitude   Latitude  T_Year\n",
       "0        1144360 -15.495200  13.932300    1997\n",
       "1        1144361 -14.838810  14.565890    1997\n",
       "2        1144362 -15.515833  14.164722    1997\n",
       "3        1144363  29.430000  -2.060000    1997\n",
       "4        1144364  29.590000  -2.070000    1997\n",
       "...          ...        ...        ...     ...\n",
       "28900    1691332  19.112700  47.627899    1997\n",
       "28901    1691333  19.962099  47.432400    1997\n",
       "28902    1691334  20.952499  46.399300    1997\n",
       "28903    1691335  -1.300000  34.916698    1997\n",
       "28904    1691336  19.291800  47.806099    1997\n",
       "\n",
       "[18976 rows x 4 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wosis  = pd.read_csv('../data/use/wosis/WoSIS_2023_December/wosis_202312_profiles.tsv', sep='\\t', low_memory=False)\n",
    "print(wosis.columns)\n",
    "wosis_profiles =wosis[['profile_id',  'longitude', 'latitude', 'fao_publication_year']].dropna(axis=0, how='any')\n",
    "wosis_profiles = wosis_profiles.rename(columns={\"profile_id\": \"ProfileID\", \"longitude\": \"Longitude\", \"latitude\": \"Latitude\", \"fao_publication_year\": \"T_Year\"})\n",
    "wosis_profiles = wosis_profiles.drop_duplicates(subset=['Longitude', 'Latitude'], keep='first', ignore_index=True)\n",
    "#convert the T_Year to int\n",
    "wosis_profiles['T_Year'] = wosis_profiles['T_Year'].astype(int)\n",
    "wosis_profiles = wosis_profiles[wosis_profiles['T_Year'] >= 1982 ]\n",
    "wosis_profiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portée requise par Earth Engine\n",
    "# SCOPES = [\"https://www.googleapis.com/auth/earthengine.readonly\"]\n",
    "\n",
    "\n",
    "\n",
    "# def authenticate_earth_engine():\n",
    "    \n",
    "#     creds = None\n",
    "\n",
    "#     # Vérifie si token.json existe (authentification précédente)\n",
    "#     if os.path.exists(\"token.json\"):\n",
    "#         creds = Credentials.from_authorized_user_file(\"token.json\", SCOPES)\n",
    "\n",
    "#     # Sinon, lance le flow OAuth pour obtenir un token\n",
    "#     if not creds or not creds.valid:\n",
    "#         if creds and creds.expired and creds.refresh_token:\n",
    "#             creds.refresh(Request())\n",
    "#         else:\n",
    "#             flow = InstalledAppFlow.from_client_secrets_file(\n",
    "#                 \"credentials.json\", SCOPES\n",
    "                \n",
    "#             )\n",
    "#             creds = flow.run_local_server(port=0)\n",
    "\n",
    "#         # Sauvegarde le token pour les prochaines fois\n",
    "#         with open(\"token.json\", \"w\") as token:\n",
    "#             token.write(creds.to_json())\n",
    "\n",
    "#     # Initialisation Earth Engine avec les credentials OAuth\n",
    "#     ee.Initialize(credentials=creds)\n",
    "#     print(\" Earth Engine authentifié avec succès !\")\n",
    "\n",
    "# # Authentification Earth Engine\n",
    "# authenticate_earth_engine()\n",
    "\n",
    "\n",
    "# Initialisation Earth Engine\n",
    "SCOPES = [\"https://www.googleapis.com/auth/earthengine.readonly\"]\n",
    "\n",
    "def initialize_earth_engine():\n",
    "    \"\"\"Initialise Earth Engine avec les credentials\"\"\"\n",
    "    try:\n",
    "        creds = Credentials.from_authorized_user_file(\"token.json\", SCOPES)\n",
    "        ee.Initialize(credentials=creds)\n",
    "        logger.info(\"Earth Engine initialisé avec succès\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur d'initialisation Earth Engine: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LANDSAT_COLLECTIONS = {\n",
    "    \"Landsat-1\": {\n",
    "        \"years\": (1972, 1978),\n",
    "        \"available_years\": (1972, 1978),\n",
    "        \"path\": \"LANDSAT/LM01/C02/T2\",\n",
    "        \"bands\": [\"B4\", \"B5\", \"B6\", \"B7\", \"QA_PIXEL\"]\n",
    "    },\n",
    "    \"Landsat-2\": {\n",
    "        \"years\": (1975, 1981),\n",
    "        \"available_years\": (1975, 1981),\n",
    "        \"path\": \"LANDSAT/LM02/C02/T1\",\n",
    "        \"bands\": [\"B4\", \"B5\", \"B6\", \"B7\", \"QA_PIXEL\"]\n",
    "    },\n",
    "    \"Landsat-3\": {\n",
    "        \"years\": (1978, 1983),\n",
    "        \"available_years\": (1978, 1983),\n",
    "        \"path\": \"LANDSAT/LM03/C02/T1\",\n",
    "        \"bands\": [\"B4\", \"B5\", \"B6\", \"B7\", \"QA_PIXEL\"]\n",
    "    },\n",
    "    \"Landsat-4\": {\n",
    "        \"years\": (1982, 1993),\n",
    "        \"available_years\": (1982, 1993),\n",
    "        \"path\": \"LANDSAT/LT04/C02/T1_L2\",\n",
    "        \"bands\": [\"SR_B1\", \"SR_B2\", \"SR_B3\", \"SR_B4\", \"SR_B5\", \"SR_B7\", \"QA_PIXEL\"]\n",
    "    },\n",
    "    \"Landsat-5\": {\n",
    "        \"years\": (1984, 2013),\n",
    "        \"available_years\": (1984, 2013),\n",
    "        \"path\": \"LANDSAT/LT05/C02/T1_L2\",\n",
    "        \"bands\": [\"SR_B1\", \"SR_B2\", \"SR_B3\", \"SR_B4\", \"SR_B5\", \"SR_B7\", \"QA_PIXEL\"]\n",
    "    },\n",
    "    \"Landsat-7\": {\n",
    "        \"years\": (1999, 2022),\n",
    "        \"available_years\": (1999, 2022),\n",
    "        \n",
    "        \"path\": \"LANDSAT/LE07/C02/T1_L2\",\n",
    "        \"bands\": [\"SR_B1\", \"SR_B2\", \"SR_B3\", \"SR_B4\", \"SR_B5\", \"SR_B7\", \"QA_PIXEL\"]\n",
    "    },\n",
    "    \"Landsat-8\": {\n",
    "        \"years\": (2013, 2025),  # en fonction de la dernière date disponible\n",
    "        \"available_years\": (2013, 2025),  # en fonction de la dernière date disponible\n",
    "        \"path\": \"LANDSAT/LC08/C02/T1_L2\",\n",
    "        \"bands\": [\"SR_B1\", \"SR_B2\", \"SR_B3\", \"SR_B4\", \"SR_B5\", \"SR_B6\", \"SR_B7\", \"SR_B10\", \"SR_B11\", \"QA_PIXEL\"]\n",
    "    },\n",
    "    \"Landsat-9\": {\n",
    "        \"years\": (2021, 2025),  # pareil, à adapter\n",
    "        \"available_years\": (2021, 2025),  # pareil, à adapter\n",
    "        \"path\": \"LANDSAT/LC09/C02/T1_L2\",\n",
    "        \"bands\": [\"SR_B1\", \"SR_B2\", \"SR_B3\", \"SR_B4\", \"SR_B5\", \"SR_B6\", \"SR_B7\", \"SR_B10\", \"SR_B11\", \"QA_PIXEL\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# for sat_name, info in LANDSAT_COLLECTIONS.items():\n",
    "#     try:\n",
    "#         collection = ee.ImageCollection(info[\"path\"])\n",
    "#         # Vérifier si la collection est vide\n",
    "#         if collection.size().getInfo() == 0:\n",
    "#             logger.warning(f\"Aucune image trouvée pour {sat_name}\")\n",
    "#         else:\n",
    "#             logger.info(f\"Collection {sat_name} initialisée avec succès\")\n",
    "#     except Exception as e:\n",
    "#         logger.error(f\"Erreur lors de l'initialisation de la collection {sat_name}: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Earth Engine initialisé avec succès\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "initialize_earth_engine()\n",
    "\n",
    "\n",
    "\n",
    "def get_appropriate_satellite(year):\n",
    "    \"\"\"Trouve le satellite Landsat approprié pour une année donnée\"\"\"\n",
    "    year = int(year)\n",
    "    \n",
    "    if year < 1972:\n",
    "        logger.debug(f\"Année {year} avant le début de Landsat, utilisation de 1972 comme proxy\")\n",
    "        year = 1972\n",
    "    available_sat = []\n",
    "    for name, info in LANDSAT_COLLECTIONS.items():\n",
    "        start, end = info[\"years\"]\n",
    "        if start <= year <= end:\n",
    "            available_sat.append((name, info[\"path\"], info[\"bands\"], year))\n",
    " \n",
    "    return  available_sat[::-1]\n",
    "      \n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_band_info(image, band_name, point):\n",
    "    try:\n",
    "        band = image.select(band_name)\n",
    "        \n",
    "        # Petite géométrie autour du point\n",
    "        region = point.buffer(30).bounds()\n",
    "\n",
    "        stats = band.reduceRegion(\n",
    "            reducer=ee.Reducer.mean(),\n",
    "            geometry=region,\n",
    "            scale=30,  # résolution Landsat\n",
    "            bestEffort=True  # évite erreur maxPixels\n",
    "        ).getInfo()\n",
    "\n",
    "        return {\n",
    "            band_name: stats.get(band_name)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Erreur pour la bande {band_name}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_landsat_data(point, target_year):\n",
    "    \"\"\"\n",
    "    Récupère les données Landsat pour un point et une année cible\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Vérifier les coordonnées valides\n",
    "        coords = point.coordinates().getInfo()\n",
    "        if coords == [0, 0] or None in coords:\n",
    "            logger.warning(\"Coordonnées invalides - point ignoré\")\n",
    "            error = \"get_landsat_data 1 : Coordonnées invalides - point ignoré\"\n",
    "            return None, None, None, None ,error\n",
    "\n",
    "        # Trouver le satellite approprié\n",
    "        # sat_name, sat_path, target_bands, effective_year = get_appropriate_satellite(target_year)\n",
    "        available_sat = get_appropriate_satellite(target_year)\n",
    "        start_date = f\"{target_year}-01-01\"\n",
    "        end_date = f\"{target_year}-12-31\"\n",
    "        # Période de recherche (±3 ans autour de l'année cible)\n",
    "        if not available_sat:\n",
    "            logger.debug(f\"Aucun satellite disponible pour l'année {target_year}\")\n",
    "            error = f\"get_landsat_data 1 : Aucun satellite disponible pour l'année {target_year}\"\n",
    "            return None, None, None, None ,error\n",
    "        count = 0\n",
    "        for sat_name, sat_path, target_bands, effective_year in available_sat:\n",
    "            logger.debug(f\"Recherche {sat_name} ({start_date} à {end_date}) pour {coords}\")\n",
    "            \n",
    "            # Créer la collection d'images\n",
    "            collection = ee.ImageCollection(sat_path) \\\n",
    "                .filterDate(start_date, end_date) \\\n",
    "                .filterBounds(point) \\\n",
    "                .sort('CLOUD_COVER', True)\n",
    "            \n",
    "            # Vérifier si des images sont disponibles\n",
    "            count = collection.size().getInfo()\n",
    "            if count > 0:\n",
    "                logger.debug(f\"{count} images trouvées pour {sat_name} ({start_date} à {end_date})\")\n",
    "                # Si des images sont trouvées, on sort de la boucle\n",
    "                break\n",
    "            \n",
    "        if count == 0:\n",
    "            logger.debug(f\"Aucune image trouvée pour {sat_name} {start_date}-{end_date}\")\n",
    "            error = f\"get_landsat_data 1 : Aucune image trouvée pour  {sat_name} {start_date}-{end_date}\"\n",
    "            return start_date, end_date, sat_name, None ,error\n",
    "\n",
    "        # Prendre l'image la moins nuageuse\n",
    "        image = collection.first()\n",
    "        if not image:\n",
    "            return start_date, end_date, sat_name, None ,f\"Aucune image dans la collection {sat_name}\"\n",
    "\n",
    "        # Vérifie les bandes valides\n",
    "        available_bands = image.bandNames().getInfo()\n",
    "        valid_bands = [b for b in target_bands if b in available_bands]\n",
    "\n",
    "        if not valid_bands:\n",
    "            return start_date, end_date, sat_name, None, f\"Aucune bande valide trouvée dans {available_bands}\"\n",
    "\n",
    "        bands_info = {}\n",
    "        for band in valid_bands:\n",
    "            info = get_band_info(image, band, point=point)\n",
    "            if info:\n",
    "                bands_info[band] = info[band]\n",
    "\n",
    "        if not bands_info:\n",
    "            return start_date, end_date, sat_name, None , \"Aucune information de bande récupérée\"\n",
    "\n",
    "        return start_date, end_date, sat_name, bands_info, None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors de la récupération des données Landsat: {str(e)}\")\n",
    "        return None, None, None, None ,f\"get_landsat_data 2 : Erreur lors de la récupération des données Landsat: {str(e)}\"\n",
    "\n",
    "\n",
    "def process_row(row):\n",
    "    \"\"\"Traite une ligne du dataframe\"\"\"\n",
    "    try:\n",
    "        profile_id, lon, lat, year = row\n",
    "        \n",
    "        # Créer le point géographique\n",
    "        point = ee.Geometry.Point(lon, lat)\n",
    "        \n",
    "        # Récupérer les données Landsat\n",
    "        start_date, end_date, sat_name, bands_info ,error = get_landsat_data(point, int(year))\n",
    "        # start_date, end_date, sat_name, bands_info = get_sentinel_data(point, start_date=\"2015-06-01\", end_date=\"2025-01-01\")\n",
    "\n",
    "        if bands_info is None:\n",
    "            logger.debug(f\"Aucune donnée pour {profile_id}\")\n",
    "            bands_data = {\"error\": error}\n",
    "        else:\n",
    "            bands_data = bands_info\n",
    "\n",
    "        return {\n",
    "            'ProfileID': profile_id,\n",
    "            'Longitude': lon,\n",
    "            'Latitude': lat,\n",
    "            'T_Year': year,\n",
    "            'Start_Date': start_date,\n",
    "            'End_Date': end_date,\n",
    "            'Satellite': sat_name,\n",
    "            \n",
    "            \n",
    "\n",
    "        } ,bands_data\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur pour le profil {row[0]}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def main( output_csv,profiles_list,limit=None):\n",
    "    \"\"\"Fonction principale\"\"\"\n",
    "    # Charger les données d'entrée\n",
    "    # df = pd.read_csv(input_csv)\n",
    "    # profiles_list = df[['ProfileID', 'Longitude', 'Latitude', 'T_Year']].values.tolist()\n",
    "    \n",
    "    # Check if the output file already exists et le creer si nécessaire\n",
    "    if not os.path.exists(output_csv):\n",
    "        with open(output_csv, 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['ProfileID', 'Longitude', 'Latitude', 'T_Year', 'Start_Date', 'End_Date', 'Satellite'])\n",
    "        \n",
    "    already_get_data = pd.read_csv(output_csv)\n",
    "\n",
    "    # Filtrer les profils déjà traités\n",
    "    processed_profiles = already_get_data['ProfileID'].tolist()\n",
    "    profiles_list = [p for p in profiles_list if p[0] not in processed_profiles]\n",
    "    print(f\"Nombre de profils à traiter : {len(profiles_list)}\")\n",
    "    # prendre les 5000 premiers profils pour le test\n",
    "    if limit:\n",
    "        profiles_list = profiles_list[:limit]\n",
    "\n",
    "    results = []\n",
    "    # Traitement parallèle\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        futures = [executor.submit(process_row, row) for row in profiles_list]\n",
    "        \n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Traitement des profils\"):\n",
    "            result , bands_data = future.result()\n",
    "            if result:\n",
    "                results.append({**result, **bands_data})\n",
    "\n",
    "    # Sauvegarder les résultats\n",
    "    output_df = pd.DataFrame(results)\n",
    "    # data_to_save = already_get_data.append(output_df, ignore_ind\"\"\"  \"\"\"ex=True)\n",
    "    data_to_save = pd.concat([already_get_data, output_df], ignore_index=True)\n",
    "\n",
    "    data_to_save.to_csv(output_csv, index=False)\n",
    "    logger.info(f\"Résultats sauvegardés dans {output_csv}\")\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de profils à traiter : 1790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traitement des profils:  13%|█▎        | 225/1790 [01:42<11:39,  2.24it/s]WARNING:googleapiclient.http:Sleeping 1.36 seconds before retry 1 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/526575593897/value:compute?prettyPrint=false&alt=json, after 503\n",
      "Traitement des profils:  24%|██▍       | 434/1790 [03:13<08:26,  2.68it/s]WARNING:googleapiclient.http:Sleeping 0.17 seconds before retry 1 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/526575593897/value:compute?prettyPrint=false&alt=json, after 503\n",
      "Traitement des profils:  50%|████▉     | 891/1790 [06:42<07:43,  1.94it/s]WARNING:googleapiclient.http:Sleeping 1.04 seconds before retry 1 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/526575593897/value:compute?prettyPrint=false&alt=json, after 503\n",
      "Traitement des profils:  50%|█████     | 900/1790 [06:46<06:05,  2.43it/s]WARNING:googleapiclient.http:Sleeping 0.96 seconds before retry 1 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/526575593897/value:compute?prettyPrint=false&alt=json, after 503\n",
      "Traitement des profils:  56%|█████▌    | 1001/1790 [07:30<04:38,  2.84it/s]WARNING:googleapiclient.http:Sleeping 1.91 seconds before retry 1 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/526575593897/value:compute?prettyPrint=false&alt=json, after 503\n",
      "Traitement des profils:  58%|█████▊    | 1031/1790 [07:44<03:48,  3.33it/s]WARNING:googleapiclient.http:Sleeping 1.18 seconds before retry 1 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/526575593897/value:compute?prettyPrint=false&alt=json, after 503\n",
      "Traitement des profils:  58%|█████▊    | 1034/1790 [07:46<06:55,  1.82it/s]WARNING:googleapiclient.http:Sleeping 1.25 seconds before retry 1 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/526575593897/value:compute?prettyPrint=false&alt=json, after 503\n",
      "Traitement des profils:  58%|█████▊    | 1040/1790 [07:48<05:11,  2.41it/s]WARNING:googleapiclient.http:Sleeping 1.21 seconds before retry 1 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/526575593897/value:compute?prettyPrint=false&alt=json, after 503\n",
      "Traitement des profils:  60%|█████▉    | 1071/1790 [08:01<03:35,  3.33it/s]WARNING:googleapiclient.http:Sleeping 0.64 seconds before retry 1 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/526575593897/value:compute?prettyPrint=false&alt=json, after 503\n",
      "WARNING:googleapiclient.http:Sleeping 0.78 seconds before retry 1 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/526575593897/value:compute?prettyPrint=false&alt=json, after 503\n",
      "Traitement des profils:  87%|████████▋ | 1562/1790 [11:44<00:58,  3.91it/s]WARNING:googleapiclient.http:Sleeping 1.06 seconds before retry 1 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/526575593897/value:compute?prettyPrint=false&alt=json, after 503\n",
      "Traitement des profils: 100%|██████████| 1790/1790 [13:39<00:00,  2.18it/s]\n",
      "INFO:__main__:Résultats sauvegardés dans lansat_ird_results_landsat8_3.csv\n"
     ]
    }
   ],
   "source": [
    "# main(\"lansat_afsp_results_all.csv\", profiles_list_afsp)\n",
    "main(\"lansat_ird_results_landsat8_3.csv\", profiles_ird.values.tolist())\n",
    "# main(\"wosis_profiles.csv\", wosis_profiles.values.tolist(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de profils à traiter : 1780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traitement des profils:   4%|▍         | 74/1780 [00:57<22:40,  1.25it/s] WARNING:googleapiclient.http:Sleeping 1.47 seconds before retry 1 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/526575593897/value:compute?prettyPrint=false&alt=json, after 503\n",
      "Traitement des profils:  62%|██████▏   | 1104/1780 [12:48<05:06,  2.20it/s] WARNING:googleapiclient.http:Sleeping 0.24 seconds before retry 1 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/526575593897/value:compute?prettyPrint=false&alt=json, after 503\n",
      "Traitement des profils: 100%|██████████| 1780/1780 [18:59<00:00,  1.56it/s]\n",
      "INFO:__main__:Résultats sauvegardés dans lansat_ird_results_landsat8.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
